{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T13:28:47.154828Z",
     "start_time": "2024-04-12T13:28:47.149095Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Set the working directory\n",
    "sys.path.append(os.getcwd() + os.sep + \"..\" + os.sep + \"..\")\n",
    "\n",
    "# Import the necessary libraries\n",
    "import pycaret.classification as pc\n",
    "import pandas as pd\n",
    "import src.scripts.mapping_answers_dict as map_dict\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.utils.class_weight import compute_class_weight, compute_sample_weight\n",
    "from math import sqrt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T13:28:48.663618Z",
     "start_time": "2024-04-12T13:28:48.466238Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Load the merged dataset\n",
    "dataset = pd.read_csv(\"../../data/processed/GYTS_dataset.csv\")\n",
    "\n",
    "ordinal_columns = [\"SmokingFriends\", \"SeenSmokerInPublicPlace\", \"SeenSmokerInEnclosedPlace\", \"SeenSmokerInHome\", \"HarmfulPassiveSmoke\", \"HardQuitSmoke\"]\n",
    "dataset[ordinal_columns] = dataset[ordinal_columns].astype('category')\n",
    "\n",
    "# Convert categorical columns\n",
    "categorical_columns = [\"State\", \"Gender\", \"Age\", \"AttractiveSmoker\", \"SmokerConfidentInCelebrations\", \"SchoolWarnings\",\n",
    "                       \"SeenHealthWarnings\", \"AntiTobaccoInEvents\"]\n",
    "dataset[categorical_columns] = dataset[categorical_columns].astype('category')\n",
    "# remove non letter, non number, non space characters from the categorical columns with regex\n",
    "\n",
    "dataset[categorical_columns] = dataset[categorical_columns].applymap(lambda x: re.sub(r'[^\\w\\s\\d]', '', x))\n",
    "\n",
    "\n",
    "# Convert boolean columns to int\n",
    "boolean_columns = [\"Smoke\", \"SeenSmokerInSchool\", \"ParentWarnings\", \"AntiTobaccoInMedia\",\n",
    "                   \"BanTobaccoOutdoors\", \"SmokingFather\", \"SmokingMother\", \"WorkingFather\",\n",
    "                   \"WorkingMother\"]\n",
    "dataset[boolean_columns] = dataset[boolean_columns].astype('int')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T13:28:54.048737Z",
     "start_time": "2024-04-12T13:28:50.537255Z"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "setup = pc.setup(data=dataset,\n",
    "                 target='Smoke',\n",
    "                 index=False,\n",
    "                 train_size=0.8,\n",
    "                 session_id=42,\n",
    "                 categorical_features=categorical_columns,\n",
    "                 ordinal_features={\n",
    "                     \"SmokingFriends\": map_dict.OR46_dict.values(),\n",
    "                     \"SeenSmokerInPublicPlace\": map_dict.CR21_dict.values(),\n",
    "                     \"SeenSmokerInEnclosedPlace\": map_dict.CR20_dict.values(),\n",
    "                     \"SeenSmokerInHome\": map_dict.CR19_dict.values(),\n",
    "                     \"HarmfulPassiveSmoke\": map_dict.CR23_dict.values(),\n",
    "                     \"HardQuitSmoke\": map_dict.CR41_dict.values(),\n",
    "                 },\n",
    "                 imputation_type=None,\n",
    "                 max_encoding_ohe=0,\n",
    "                 encoding_method=OneHotEncoder(dtype=int, sparse_output=False),\n",
    "                 n_jobs=10\n",
    "                 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute the class weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T13:29:15.063320Z",
     "start_time": "2024-04-12T13:29:15.048072Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "classes = dataset['Smoke'].unique()\n",
    "\n",
    "class_weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=pc.get_config(\"y_train_transformed\"))\n",
    "sqrt_weights = [sqrt(weight) for weight in class_weights]\n",
    "\n",
    "class_weights = dict(zip(classes, class_weights))\n",
    "sqrt_weights = dict(zip(classes, sqrt_weights))\n",
    "\n",
    "print(class_weights)\n",
    "print(sqrt_weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best model within the class-weight supporting ones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-12T13:30:33.065919Z",
     "start_time": "2024-04-12T13:30:22.383861Z"
    }
   },
   "outputs": [],
   "source": [
    "from IPython.display import display, HTML\n",
    "#all_models = [ 'lr', 'knn', 'nb', 'dt', 'svm', 'ridge', 'rf', 'qda', 'ada', 'gbc', 'lda', 'et', 'xgboost', 'lightgbm', 'catboost'] #'rbfsvm', 'gpc', 'mlp'\n",
    "\n",
    "# Models that support class weights\n",
    "weighted_model_id =[ 'lr', 'dt', 'svm' , 'ridge', 'rf', 'et', 'lightgbm'] # 'rbfsvm'\n",
    "models = {}\n",
    "predicts = pd.DataFrame()\n",
    "cv_results = pd.DataFrame()\n",
    "\n",
    "for model_id in weighted_model_id:\n",
    "    try:\n",
    "        # get model name from setup\n",
    "        model_name = pc.models().loc[model_id].Name\n",
    "        \n",
    "        display(HTML(f\"<h2>Training {model_name}</h2>\"))\n",
    "        model = pc.create_model(model_id, verbose=True, class_weight=sqrt_weights)\n",
    "        models[model_id] = model\n",
    "        \n",
    "        cv =  pc.pull()\n",
    "        cv = cv.loc['Mean']\n",
    "        cv = cv.to_frame().transpose()\n",
    "        \n",
    "        cv.index = [model_name] # set index to model name\n",
    "        cv_results = pd.concat([cv_results, cv])\n",
    "        \n",
    "        display(HTML(f\"<h3>Predicting {model_name}</h3>\"))\n",
    "        pc.predict_model(model)\n",
    "        predict = pc.pull()\n",
    "        predicts = pd.concat([predicts, predict])\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "\n",
    "# Sort the models by MCC\n",
    "cv_results = cv_results.sort_values('MCC', ascending=False)\n",
    "predicts = predicts.sort_values('MCC', ascending=False)\n",
    "\n",
    "display(HTML(f\"<h2>Cross validation mean results</h2>{cv_results.to_html()}\"))\n",
    "display(HTML(f\"<h2>Predictions result</h2>{predicts.to_html()}\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing best model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-03-26T12:59:08.827365800Z",
     "start_time": "2024-03-26T12:59:08.394595300Z"
    }
   },
   "outputs": [],
   "source": [
    "lgbm_model = models['lightgbm']\n",
    "lgbm_tuned_model = pc.tune_model(lgbm_model, optimize='Accuracy', search_library='optuna', search_algorithm='tpe')\n",
    "lgbm_ensemble_model = pc.ensemble_model(lgbm_tuned_model, method='Bagging', optimize='Accuracy')\n",
    "\n",
    "\n",
    "print(\"Base LightGBM Model performance on test data\")\n",
    "pc.predict_model(lgbm_model)\n",
    "print(\"Tuned LightGBM Model performance on test data\")\n",
    "pc.predict_model(lgbm_tuned_model)\n",
    "print(\"Ensemble LightGBM Model performance on test data\")\n",
    "pc.predict_model(lgbm_ensemble_model)\n",
    "\n",
    "\n",
    "et_model = models['et']\n",
    "et_tuned_model = pc.tune_model(et_model, optimize='Accuracy', search_library='optuna', search_algorithm='tpe')\n",
    "et_ensemble_model = pc.ensemble_model(et_tuned_model, method='Bagging', optimize='Accuracy')\n",
    "\n",
    "print(\"Base Extra Trees Model performance on test data\")\n",
    "pc.predict_model(et_model)\n",
    "print(\"Tuned Extra Trees Model performance on test data\")\n",
    "pc.predict_model(et_tuned_model)\n",
    "print(\"Ensemble Extra Trees Model performance on test data\")\n",
    "pc.predict_model(et_ensemble_model)\n",
    "\n",
    "rf_model = models['rf']\n",
    "rf_tuned_model = pc.tune_model(rf_model, optimize='Accuracy', search_library='optuna', search_algorithm='tpe')\n",
    "rf_ensemble_model = pc.ensemble_model(rf_tuned_model, method='Bagging', optimize='Accuracy', probability_threshold=0.35)\n",
    "\n",
    "print(\"Base Random Forest Model performance on test data\")\n",
    "pc.predict_model(rf_model)\n",
    "print(\"Tuned Random Forest Model performance on test data\")\n",
    "pc.predict_model(rf_tuned_model)\n",
    "print(\"Ensemble Random Forest Model performance on test data\")\n",
    "pc.predict_model(rf_ensemble_model)\n",
    "\n",
    "\n",
    "blended_model = pc.blend_models(estimator_list=[lgbm_ensemble_model, et_ensemble_model, rf_ensemble_model], optimize='Accuracy') \n",
    "print(\"Blended Model performance on test data\")\n",
    "pc.predict_model(blended_model)\n",
    "\n",
    "\n",
    "# pc.plot_model(blended_model, plot='threshold')\n",
    "pc.evaluate_model(blended_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.save_model(blended_model, \"../../data/models/final_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any, Dict, Optional\n",
    "from shap import sample\n",
    "from explainerdashboard import ClassifierExplainer, ExplainerDashboard\n",
    "from pycaret.utils.generic import get_label_encoder\n",
    "\n",
    "def dashboard(\n",
    "        estimator,\n",
    "        display_format: str = \"dash\",\n",
    "        dashboard_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        run_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        This function generates the interactive dashboard for a trained model. The\n",
    "        dashboard is implemented using ExplainerDashboard (explainerdashboard.readthedocs.io)\n",
    "\n",
    "\n",
    "        Example\n",
    "        -------\n",
    "        >>> from pycaret.datasets import get_data\n",
    "        >>> juice = get_data('juice')\n",
    "        >>> from pycaret.classification import *\n",
    "        >>> exp_name = setup(data = juice,  target = 'Purchase')\n",
    "        >>> lr = create_model('lr')\n",
    "        >>> dashboard(lr)\n",
    "\n",
    "\n",
    "        estimator: scikit-learn compatible object\n",
    "            Trained model object\n",
    "\n",
    "\n",
    "        display_format: str, default = 'dash'\n",
    "            Render mode for the dashboard. The default is set to ``dash`` which will\n",
    "            render a dashboard in browser. There are four possible options:\n",
    "\n",
    "            - 'dash' - displays the dashboard in browser\n",
    "            - 'inline' - displays the dashboard in the jupyter notebook cell.\n",
    "            - 'jupyterlab' - displays the dashboard in jupyterlab pane.\n",
    "            - 'external' - displays the dashboard in a separate tab. (use in Colab)\n",
    "\n",
    "\n",
    "        dashboard_kwargs: dict, default = {} (empty dict)\n",
    "            Dictionary of arguments passed to the ``ExplainerDashboard`` class.\n",
    "\n",
    "\n",
    "        run_kwargs: dict, default = {} (empty dict)\n",
    "            Dictionary of arguments passed to the ``run`` method of ``ExplainerDashboard``.\n",
    "\n",
    "        **kwargs:\n",
    "            Additional keyword arguments to pass to the ``ClassifierExplainer`` or\n",
    "            ``RegressionExplainer`` class.\n",
    "\n",
    "\n",
    "        Returns:\n",
    "            ExplainerDashboard\n",
    "        \"\"\"\n",
    "\n",
    "        dashboard_kwargs = dashboard_kwargs or {}\n",
    "        run_kwargs = run_kwargs or {}\n",
    "\n",
    "        le = get_label_encoder(pc.get_config(\"pipeline\"))\n",
    "        if le:\n",
    "            labels_ = list(le.classes_)\n",
    "        else:\n",
    "            labels_ = None\n",
    "\n",
    "        seed = pc.get_config(\"seed\")\n",
    "        # Replacing chars which dash doesn't accept for column name `.` , `{`, `}`\n",
    "        X_test_df = sample(pc.get_config('X_test_transformed').copy(), 1000, random_state=seed)\n",
    "        X_test_df.columns = [\n",
    "            col.replace(\".\", \"__\").replace(\"{\", \"__\").replace(\"}\", \"__\")\n",
    "            for col in X_test_df.columns\n",
    "        ]\n",
    "\n",
    "   \n",
    "        y_test_df = sample(pc.get_config('y_test_transformed').copy(), 1000, random_state=seed)\n",
    "        \n",
    "        onehotencoded = categorical_columns.copy()\n",
    "        onehotencoded.remove(\"Gender\")\n",
    "        explainer = ClassifierExplainer(\n",
    "            model=estimator, \n",
    "            X=X_test_df, \n",
    "            y=y_test_df, \n",
    "            labels=labels_, \n",
    "            n_jobs=10, \n",
    "            cats=onehotencoded,\n",
    "            **kwargs,\n",
    "        )\n",
    "        \n",
    "        explainer_dashboard = ExplainerDashboard(\n",
    "            explainer, mode=display_format, **dashboard_kwargs\n",
    "        )\n",
    "        \n",
    "        explainer_dashboard.run(**run_kwargs)\n",
    "        return explainer_dashboard\n",
    "\n",
    "explainer_dashboard = dashboard(estimator=blended_model, display_format='external', shap='kernel', dashboard_kwargs={\"port\": 8100})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exporting to yaml file the dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "explainer_dashboard.to_yaml(\"../../data/models/dashboard_config.yaml\", dump_explainer=True, explainerfile=\"final_model_explainer.dill\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importazione del modello\n",
    "Siccome l'addestramento del modello richiede molto tempo e risorse, il modello è stato salvato in un file .pkl e verrà importato in questa sezione del notebook, per poi essere utilizzato per fare predizioni sul dataset di test. Inoltre può essere importata la dashboard per visualizzare i risultati ottenuti."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = pc.load_model(\"../../data/models/final_model\")\n",
    "pc.evaluate_model(final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from explainerdashboard import ExplainerDashboard\n",
    "explainer_dashboard2 = ExplainerDashboard.from_config(\"../../data/models/final_model_explainer.dill\", \"../../data/models/dashboard_config.yaml\",)\n",
    "explainer_dashboard2.run(port=5502)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
