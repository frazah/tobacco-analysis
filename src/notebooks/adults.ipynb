{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "# set the working directory\n",
    "sys.path.append(os.getcwd() + os.sep + \"..\" + os.sep + \"..\")\n",
    "\n",
    "import pandas as pd\n",
    "import pycaret.classification as pc\n",
    "from imblearn.over_sampling import SMOTE, SMOTEN, ADASYN\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import  train_test_split\n",
    "\n",
    "# import from ../script/data.py in scripts folder\n",
    "from src.scripts.data import CR8_smoke_dict, OR45_dict "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "greece_dict = {1:1, 2:1, 3:2, 4:2, 5:3, 6:3, 7:4, 8:5, 9:6}\n",
    "poland_dict = {1:1, 2:1, 3:2, 4:3, 5:4, 6:4, 7:4, 8:5, 9:6}\n",
    "romania_dict = {1:1, 2:2, 3:3, 4:4, 5:4, 6:4, 7:4, 8:5, 9:5, 10:6}\n",
    "england_dict = {\"No Qualification\": 1, \"GCSE/O Level\": 2, \"GCSE/CSE\": 3, \"A Levels\": 4, \"ONC/BTEC\": 4, \"Other/Sub Degree\": 4, \"Higher/Sub Degree\": 5, \"Degree\": 5}\n",
    "\n",
    "def read_dataframes(folder_path):\n",
    "    file_list = [f for f in os.listdir(folder_path) if f.endswith('.sas7bdat')]\n",
    "    print(file_list)\n",
    "    dataframes = {file: pd.read_sas(os.path.join(folder_path, file)) for file in file_list}\n",
    "    return dataframes\n",
    "\n",
    "\n",
    "def get_common_columns(dataframes):\n",
    "    # rename all columns to lower case\n",
    "    for df in dataframes.values():\n",
    "        df.columns = df.columns.str.upper()\n",
    "    \n",
    "    common_columns = dataframes[list(dataframes.keys())[0]].columns\n",
    "    for df in dataframes.values():\n",
    "        common_columns = common_columns.intersection(df.columns)\n",
    "    return common_columns\n",
    "\n",
    "\n",
    "def preprocess_dataframes(dataframes, common_columns):\n",
    "    merged_df = pd.DataFrame()\n",
    "    for i, (file, df) in enumerate(dataframes.items()):\n",
    "        df = df[common_columns]\n",
    "        # df.insert(0, \"State\", file.split(\" \")[2])\n",
    "        \n",
    "        state = file.split(\" \")[2].split(\".\")[0]\n",
    "        if state == \"Greece\":\n",
    "            df[\"A04\"] = df[\"A04\"].map(greece_dict)\n",
    "        elif state == \"Poland\":\n",
    "            df[\"A04\"] = df[\"A04\"].map(poland_dict)\n",
    "        elif state == \"Romania\":\n",
    "            df[\"A04\"] = df[\"A04\"].map(romania_dict)\n",
    "        \n",
    "        df.insert(0, \"State\", i)\n",
    "        merged_df = pd.concat([merged_df, df])\n",
    "        \n",
    "    merged_df.rename(columns={\"AGE\": \"Age\"}, inplace=True)\n",
    "    merged_df.rename(columns={\"A01\": \"Gender\"}, inplace=True)\n",
    "    merged_df.rename(columns={\"B01\": \"Smoke\"}, inplace=True)\n",
    "    merged_df[\"Smoke\"] = merged_df[\"Smoke\"].map({1: True, 2: True, 3: False})\n",
    "    merged_df.rename(columns={\"A04\": \"Education\"}, inplace=True)    \n",
    "    merged_df.rename(columns={\"A11\": \"MaritalStatus\"}, inplace=True) \n",
    "\n",
    "    england_df = pd.read_csv(\"../../data/raw/smoking_england.csv\")\n",
    "    england_df.insert(0, \"State\", i+1)\n",
    "    \n",
    "    # rename all column of england_df to Title Case\n",
    "    england_df.columns = england_df.columns.str.title()\n",
    "    \n",
    "    england_df[\"Smoke\"] = england_df[\"Smoke\"].map({\"Yes\": True, \"No\": False})\n",
    "    england_df[\"Education\"] = england_df[\"Highest_Qualification\"].map(england_dict)\n",
    "    england_df[\"Gender\"] = england_df[\"Gender\"].map({\"Male\":1, \"Female\":2})\n",
    "    england_df[\"MaritalStatus\"] = england_df[\"Marital_Status\"].map({\"Single\": 1, \"Married\": 2, \"Separated\":3, \"Divorced\": 4, \"Widowed\": 5})\n",
    "    merged_df = pd.concat([merged_df, england_df])\n",
    "    # merged_df = england_df\n",
    "\n",
    "\n",
    "    return merged_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# open sas7bdat file\n",
    "# file = pd.read_sas('../../data/raw/GATS/GATS_Greece_National_2013_SAS/GREECE_PUBLIC_USE_11Mar2015.sas7bdat')\n",
    "\n",
    "# Read dataframes from GYTS folder\n",
    "dataframes = read_dataframes(\"../../data/raw/GATS/\")\n",
    "\n",
    "for df in dataframes.values():\n",
    "    if \"A11\" not in df.columns:\n",
    "        df[\"A11\"] = None\n",
    "\n",
    "# Find common columns in all dataframes\n",
    "common_columns = get_common_columns(dataframes)\n",
    "print([c for c in common_columns])\n",
    "\n",
    "# Preprocess dataframes\n",
    "merged_df = preprocess_dataframes(dataframes, common_columns)\n",
    "\n",
    "# count number of A11 values\n",
    "# print(merged_df[\"MaritalStatus\"].value_counts())\n",
    "\n",
    "# Drop rows with missing values\n",
    "# merged_df = merged_df.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df = merged_df[['State', 'Age', 'Gender', 'Smoke', 'Education', 'MaritalStatus']]\n",
    "\n",
    "# merged_df = merged_df.dropna()\n",
    "\n",
    "#use IterativeImputer to fill missing values of Education and MaritalStatus\n",
    "#imp = IterativeImputer(max_iter=10, random_state=0)\n",
    "#merged_df = pd.DataFrame(imp.fit_transform(merged_df), columns=merged_df.columns)\n",
    "\n",
    "\n",
    "merged_df[\"State\"] = merged_df[\"State\"].astype('int').astype('category')\n",
    "merged_df['Age'] = merged_df['Age'].astype('int')\n",
    "merged_df['Gender'] = merged_df['Gender'].astype('int').astype('category')\n",
    "merged_df[\"Education\"] = merged_df[\"Education\"].astype('category')\n",
    "merged_df[\"MaritalStatus\"] = merged_df[\"MaritalStatus\"].astype('category')\n",
    "merged_df[\"Smoke\"] = merged_df[\"Smoke\"].astype('bool')\n",
    "\n",
    "\n",
    "\n",
    "# print the number of missing values in each column\n",
    "print(merged_df.isnull().sum())\n",
    "\n",
    "merged_df.tail()\n",
    "\n",
    "# 1 no formal education\n",
    "# 2 primary education\n",
    "# 3 secondary school\n",
    "# 4 high school\n",
    "# 5 university\n",
    "# 6 postgraduate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "train, test = train_test_split(merged_df, test_size=0.2, random_state=42)\n",
    "test.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Split the train set into features and target\n",
    "X = train.drop(columns=[\"Smoke\"])\n",
    "y = train[\"Smoke\"]\n",
    "\n",
    "# Convert y values to categorical values\n",
    "lab = preprocessing.LabelEncoder()\n",
    "y = lab.fit_transform(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = pd.DataFrame(y, columns=[\"Smoke\"])\n",
    "y.reset_index(drop=True, inplace=True)\n",
    "X.reset_index(drop=True, inplace=True)\n",
    "train = pd.concat([X, y] , axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "+ Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smote = SMOTE()\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)\n",
    "\n",
    "# Convert array to dataframe\n",
    "y_resampled = pd.DataFrame(y_resampled, columns=['Smoke'])\n",
    "# y = pd.DataFrame(y, columns=['Smoke'])\n",
    "\n",
    "# remove index\n",
    "# X.reset_index(drop=True, inplace=True)\n",
    "# y.reset_index(drop=True, inplace=True)\n",
    "X_resampled.reset_index(drop=True, inplace=True)\n",
    "\n",
    "train = pd.concat([X_resampled, y_resampled], axis=1)\n",
    "# df_resampled = pd.concat([X, y], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comparing models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "setup = pc.setup(data=train,\n",
    "                target='Smoke',\n",
    "                session_id=123,\n",
    "                # normalize=True,\n",
    "                transformation=True,\n",
    "                remove_multicollinearity=True, multicollinearity_threshold=0.95, max_encoding_ohe=0,\n",
    "                fix_imbalance=True, fix_imbalance_method=ADASYN(),\n",
    "                imputation_type='iterative',\n",
    "                categorical_features=['State', 'Gender', 'Education', 'MaritalStatus'],\n",
    "                numeric_features=['Age'])\n",
    "\n",
    "pc.compare_models()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choosing best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extra Trees Classifier\n",
    "model = pc.create_model('lightgbm')\n",
    "\n",
    "\n",
    "# pc.plot_model(model, plot='auc')\n",
    "pc.plot_model(model, plot='pr')\n",
    "pc.plot_model(model, plot='feature')\n",
    "pc.plot_model(model, plot='feature_all',scale=3)\n",
    "pc.plot_model(model, plot='confusion_matrix')\n",
    "\n",
    "final_rf = pc.finalize_model(model)\n",
    "# final_rf\n",
    "pc.predict_model(final_rf)\n",
    "# print(final_rf)\n",
    "\n",
    "unseen_predictions = pc.predict_model(final_rf, data=test)\n",
    "print(unseen_predictions.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = ExtraTreesClassifier(model)\n",
    "\n",
    "pd.DataFrame({'Feature': pc.get_config('X_train').columns, 'Value' : abs(model.feature_importances_)}).sort_values(by='Value', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.interpret_model(model, plot='summary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.interpret_model(model, plot='correlation', feature='Age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pc.interpret_model(model, plot='reason', feature='Age')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import shap\n",
    "shap.plots.bar(shap_values.abs.mean(0))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
